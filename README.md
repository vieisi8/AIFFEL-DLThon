# AIFFEL-DLThon

## AIFFEL-DLThon??
  - AIFFEL 과정중 진행한 데이터톤(Datathon)을 의미
  - 총 6일간 진행(24.10.02~24.10.07)
  - 자세한 정보는 아래 이미지를 참조 
![image](https://github.com/user-attachments/assets/c2f375eb-40b6-4b7b-9dec-adab8fd00fdc)
![image](https://github.com/user-attachments/assets/3a2240e4-f036-4027-91d2-5b1f799fa587)

## 📚 기술 스택
  - AI
    - Hugging Face
    - WandB
  - Back-end
    - Python
    - EDA
    - Matplotlib
    - Seaborn
    - Sklearn
    - TensorFlow
    - PyTorch

## 🧑‍💻 프로젝트 기여
  - 사전 훈련 모델 선택, Wandb을 통한 사전 훈련 모델 Fine-tuning
  - Label 예측

## 📈 Leaderboard 순위
![image](https://github.com/user-attachments/assets/3109c422-4364-4d94-9c2f-000384ee4ccb)
  - 6개 팀 중 3위로 마무리

## ⚠️ 트러블슈팅

### 🤝 협업 트러블슈팅 
  - 문제 상황:
    - 데이터 전처리를 담당한 팀원의 작업이 지연되면서, 모델을 적절히 Fine-tuning하는 데 어려움이 발생함.
  - 원인 분석:
    - 해당 팀원이 해당 도메인의 전공자로서 더 정확한 전처리를 목표로 하다 보니, 작업이 예상보다 지연됨.
    - 데이터 정제 기준이 명확하지 않아, 어느 정도까지 전처리를 해야 하는지 팀원 간 인식 차이가 있었음.
  - 해결 과정:
    - 팀원들과 논의하여 전처리의 범위와 기준을 명확하게 설정.
    - 일정 조율을 통해 데이터 전처리 진행 상황을 공유하고 조정.
  - 결과 및 교훈:
    - 이후 일정에 맞게 데이터 전처리가 완료되어, 이후 단계(모델 Fine-tuning)를 원활하게 진행할 수 있었음.
    - 도메인 전문가가 전처리를 담당할 경우, 작업 범위를 명확히 정의하는 것이 중요하다는 점을 배움
